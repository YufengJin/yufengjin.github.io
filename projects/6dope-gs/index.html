<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- SEO Meta -->
  <title>6DOPE-GS: Online 6D Object Pose Estimation using Gaussian Splatting</title>
  <meta name="description" content="6DOPE-GS is a real-time method for online 6D object pose estimation and tracking using Gaussian Splatting. It offers accurate model-free pose estimation from RGB-D video streams with 5× speedup over existing methods.">
  <meta name="keywords" content="6DOPE-GS, 6D object pose estimation, Gaussian Splatting, object tracking, RGB-D, SLAM, real-time vision, robotics">

  <!-- Open Graph (Facebook, Slack, etc.) -->
  <meta property="og:title" content="6DOPE-GS: Online 6D Object Pose Estimation using Gaussian Splatting" />
  <meta property="og:description" content="6DOPE-GS performs efficient and accurate 6D object pose estimation and reconstruction using Gaussian Splatting. Suitable for robotics and real-time vision." />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://yufengjin.github.io/projects/6dope-gs/" />
<!-- Optional: image preview -->
<!-- <meta property="og:image" content="https://yufengjin.github.io/projects/6dope-gs/resources/overview.jpg" /> -->

  <!-- <meta name="description"
    content="We propose Visual Geometry Grounded Transformer (VGGT), a feed-forward neural network that directly predicts all key 3D scene attributes from single or multiple (up to hundreds) image views within seconds.">
  <meta name="keywords" content="VGGT, Camera, Point map, Depth map, 3D reconstruction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VGGT: Visual Geometry Grounded Transformer</title>


  <meta property="og:title" content="VGGT: Visual Geometry Grounded Transformer." />
  <meta property="og:description"
    content="We propose Visual Geometry Grounded Transformer (VGGT), a feed-forward neural network that directly predicts all key 3D scene attributes from single or multiple (up to hundreds) image views within seconds." /> -->
  <!-- Twitter automatically scrapes this. Go to https://cards-dev.twitter.com/validator?
      if you update and want to force Twitter to re-scrape. -->
  <!-- <meta property="twitter:card" content="summary" />
  <meta property="twitter:title" content="VGGT: Visual Geometry Grounded Transformer." />
  <meta property="twitter:description"
    content="We propose Visual Geometry Grounded Transformer (VGGT), a feed-forward neural network that directly predicts all key 3D scene attributes from single or multiple (up to hundreds) image views within seconds." /> -->
  <!-- <meta property="twitter:image"         content="https://3dmagicpony.github.io/resources/overview.jpg" /> -->

  <!-- MathJax library -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-TSQGH8Q0WV"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-TSQGH8Q0WV');
  </script>
  <script type="module" src="https://ajax.googleapis.com/ajax/libs/model-viewer/4.0.0/model-viewer.min.js"></script>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-4 publication-title" style="font-size: 2rem;">6DOPE-GS: Online 6D Object Pose Estimation using Gaussian Splatting</h1>
       
            <div class="is-size-5 publication-authors">
                <span class="author-block"><strong>Yufeng Jin</strong><sup>1,2</sup>,</span>
                &nbsp;&nbsp;&nbsp;
                <span class="author-block">
                  <a href="https://pearl-lab.com/vignesh-prasad/">Vignesh Prasad</a><sup>1</sup>,
                </span>
                &nbsp;&nbsp;&nbsp;
                <span class="author-block">
                  <a href="https://irosalab.com/snehal-jauhri/">Snehal Jauhri</a><sup>1</sup>,
                </span>
                &nbsp;&nbsp;&nbsp;
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/mathias-franzius-86b17b2b4/">Mathias Franzius</a><sup>2</sup>,
                </span>
                &nbsp;&nbsp;&nbsp;
                <span class="author-block">
                  <a href="https://pearl-lab.com/people/georgia-chalvatzaki/">Georgia Chalvatzaki</a><sup>1,3</sup>
                </span>
              </div>

              <div class="is-size-5 publication-authors" style="margin-bottom: 10px;">
                <span class="author-block" style="margin-right: 1.5em;"><sup>1</sup> TU Darmstadt</span>
                <span class="author-block" style="margin-right: 1.5em;"><sup>2</sup> Honda Research Europe</span>
                <span class="author-block"><sup>3</sup> Hessian.AI</span>
                <!-- <span class="author-block"><sup>1</sup>TU Darmstadt</span>
                <span class="author-block"><sup>2</sup>Honda Research Europe</span>
                <span class="author-block"><sup>3</sup>Hessian.AI</span> -->
              </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2412.01543" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Code Link (coming soon) -->
                <span class="link-block">
                  <a class="external-link button is-normal is-rounded is-dark is-disabled" style="pointer-events: none; opacity: 0.6;">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming Soon)</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <style>
    .video-border {
      display: inline-block;
      padding: 2px; /* adjust thickness of your 'border' */
      border-radius: 4px;
      background: linear-gradient(45deg, #ff9a9e, #fad0c4); /* try different gradient colors */
    }
    .video-border video {
      display: block;
      border: none;
      border-radius: 4px; /* match the wrapper for a consistent look */
    }
  </style>

  <style>
    #teaser-video {
      max-width: 85%;
      margin: 0 auto;
      display: block;
      border: none; /* remove the solid border */
      border-radius: 4px;
      box-shadow: 0 4px 10px rgba(0, 0, 0, 0.15);
    }
    
    #architecture-img {
      width: 90%;
      margin: 0 auto;
      display: block;
      border: none;
      border-radius: 0; /* removed border radius */
      box-shadow: none; /* removed box shadow */
    }
    
    /* Enhanced style to further reduce space between buttons and teaser video */
    .hero.teaser {
      padding-top: 0;
      margin-top: -3rem; /* Added negative margin to pull the teaser section up */
    }
    .hero.teaser .hero-body {
      padding-top: 0; /* Reduced from 1rem to 0 */
    }
  </style>
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser-video" autoplay muted loop playsinline height="100%">
          <source src="./resources/6DOPE_GS.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle" style="text-align: center;"></h2>
      </div>
    </div>
  </section>


  <section class="section" style="padding-top: 1rem;">
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width has-text-centered">
          <h2 class="title is-4" style="font-weight: 700;">Abstract</h2>
          <div class="content has-text-justified">
            <p>
            Efficient and accurate object pose estimation is crucial for applications such as AR, autonomous driving, and robotics. While model-based 6D pose methods show strong performance, model-free approaches often suffer from high computational cost in real-time RGB-D settings.
            We introduce <b>6DOPE-GS</b>, a method for online 6D object pose estimation and tracking using a single RGB-D camera. It leverages fast differentiable rendering via Gaussian Splatting to jointly optimize object pose and 3D reconstruction in real time.
            To improve robustness and speed, our approach combines incremental 2D Gaussian Splatting with dynamic keyframe selection and opacity-based pruning. This ensures high spatial coverage and adaptive Gaussian control. Experiments on HO3D and YCBInEOAT demonstrate that 6DOPE-GS achieves performance comparable to state-of-the-art model-free baselines while offering a 5× speedup, enabling efficient tracking and reconstruction in real-world scenarios.
          </p>
          </div>
          <br>

          <h2 class="title is-4" style="font-weight: 700;">Method</h2>
          <div class="content has-text-justified">
            <p>
              6DOPE-GS begins by segmenting the target object using SAM2 in the first RGB-D frame, and tracks it across the sequence. Keyframes are selected via LoFTR correspondences and initialized with coarse poses using bundle adjustment. These keyframes are jointly optimized with 2D Gaussians through differentiable rendering for accurate pose refinement and object reconstruction. A dynamic keyframe selection strategy improves spatial coverage, while an adaptive Gaussian pruning mechanism ensures efficiency. The final keyframe poses guide an online pose graph for continuous tracking during runtime.
            </p>
          </div>
          <div class="content has-text-centered">
            <!-- <img id="teaser" src="https://placehold.co/600x400" alt="Teaser image" style="width: 100%;"> -->
            <img id="architecture-img" src="./resources/pipeline_new.drawio.png" alt="Architecture">
          </div>
          <br>


        </div>
      </div>
    </div>
  </section>
  
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title is-4" style="font-weight: 700;">BibTeX</h2>
      <pre><code>@article{jin20246dope,
  title={6DOPE-GS: Online 6D Object Pose Estimation using Gaussian Splatting},
  author={Jin, Yufeng and Prasad, Vignesh and Jauhri, Snehal and Franzius, Mathias and Chalvatzaki, Georgia},
  journal={arXiv preprint arXiv:2412.01543},
  year={2024}
}</code></pre>
    </div>
  </section>

  
<!-- 
  <section class="section" id="Acknowledgements" style="padding-top: 0rem;">
    <div class="container is-max-desktop content">
      <h2 class="title is-4" style="font-weight: 700;">Acknowledgements</h2>
      <p>
        Jianyuan Wang is supported by Facebook Research.
      </p>
      <p>
        We are deeply grateful for the insightful discussions and invaluable support provided by Stanislaw Szymanowicz,  Junyu Xie, Johannes Schönberger, Shangzhe Wu, Chuanxia Zheng, Junlin Han, Ang Cao, Nikhil Keetha, Chris Offner, Shangzhan Zhang, Yuxi Xiao, Qianqian Wang, Yinghao Xu, Ceyuan Yang, Nan Xue, Yujun Shen, Roman Shapovalov, João Henriques, and Andrew Zisserman.
      </p>
      <p>
        We appreciate the great examples provided by Depth-Anything-V2, Metric3D V2, MoGe, and FLARE.
      </p>
      <p>
        Special thanks to Jianing Yang, Ang Cao, Zhenggang Tang, Yuchen Fan, Shangzhan Zhang, and Qianqian Wang for providing or verifying the results of their methods.
      </p>
    </div>
  </section> -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This webpage template is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>,
              under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0 License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
  <script src="static/js/comparison.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      // Set initial camera positions for all model viewers
      const initialModelViewers = [
        document.getElementById('QualitativeResult'),
        document.getElementById('modelViewerComparison1'),
        document.getElementById('modelViewerComparison2'),
        document.getElementById('modelViewerComparison3')
      ];
      
      // Apply consistent initial camera settings to all model viewers
      initialModelViewers.forEach(viewer => {
        if (viewer) {
          viewer.addEventListener('load', () => {
            viewer.cameraOrbit = "180deg 70deg auto";
            if (viewer.resetTurntableRotation) {
              viewer.resetTurntableRotation(0);
            }
            viewer.jumpCameraToGoal();
          });
        }
      });
      
      // Handle comparison thumbnails
      const firstComparisonThumbnail = document.querySelector('#thumbnail-comparison video, #thumbnail-comparison img');
      if (firstComparisonThumbnail) {
        firstComparisonThumbnail.classList.add('thumbnail-selected');
        // If it's a video, play it
        if (firstComparisonThumbnail.tagName.toLowerCase() === 'video') {
          firstComparisonThumbnail.play();
        }
      }
      
      document.querySelectorAll('#thumbnail-comparison img, #thumbnail-comparison video').forEach(el => {
        el.addEventListener('click', () => {
          const name = el.getAttribute('name');
          
          // Update model viewers with the corresponding GLB files
          const modelViewer1 = document.getElementById('modelViewerComparison1');
          const modelViewer2 = document.getElementById('modelViewerComparison2');
          const modelViewer3 = document.getElementById('modelViewerComparison3');
          
          modelViewer1.setAttribute('src', `resources/comparison/ours/${name}.glb`);
          modelViewer2.setAttribute('src', `resources/comparison/dust3r/${name}.glb`);
          
          // For the third viewer, check the dropdown selection
          const baseline = document.getElementById('comparisonBaselineSelection').value;
          modelViewer3.setAttribute('src', `resources/comparison/${baseline}/${name}.glb`);
          
          // Reset camera positions
          [modelViewer1, modelViewer2, modelViewer3].forEach(viewer => {
            viewer.cameraOrbit = "180deg 70deg auto";
            if (viewer.resetTurntableRotation) {
              viewer.resetTurntableRotation(0);
            }
            viewer.jumpCameraToGoal();
          });

          // Remove selection class from all elements
          document.querySelectorAll('#thumbnail-comparison img, #thumbnail-comparison video').forEach(element => {
            element.classList.remove('thumbnail-selected');
          });
          
          // Add selection class to clicked element
          el.classList.add('thumbnail-selected');
          
          // Play video if it's a video element
          if (el.tagName.toLowerCase() === 'video') {
            el.play();
          }
          
          // Pause all other videos
          document.querySelectorAll('#thumbnail-comparison video').forEach(video => {
            if (video !== el) {
              video.pause();
              video.currentTime = 0;
            }
          });
        });
      });
      
      // Handle dropdown change for the third comparison model
      document.getElementById('comparisonBaselineSelection').addEventListener('change', function() {
        const selectedName = document.querySelector('#thumbnail-comparison .thumbnail-selected').getAttribute('name');
        const baseline = this.value;
        document.getElementById('modelViewerComparison3').setAttribute('src', `resources/comparison/${baseline}/${selectedName}.glb`);
      });
    });
  </script>

</body>

</html>
